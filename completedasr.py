# -*- coding: utf-8 -*-
"""completedASR.ipynb

Automatically generated by Colaboratory.

"""

!pip install jiwer

# Commented out IPython magic to ensure Python compatibility.
# necessary imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from IPython import display
from jiwer import wer
import os

from google.colab import drive
drive.mount("/content/drive")

# preprocessing data and creating tensorflow data
path = "/content/drive/MyDrive/explorer/main_asr/dataset/labels/line_index_male.tsv"

filenames = []
labels = []

with open(path, "r", encoding="utf-8") as file:
  contents = file.readlines()
  for c in contents:
    file_and_trans = c.strip().split("\t")
    filenames.append(file_and_trans[0])
    labels.append(file_and_trans[1])


print("total files : ", len(filenames))

split = int(len(filenames)*0.90)

train_files = filenames[:split]
train_labels = labels[:split]

valid_files = filenames[split:]
valid_labels = labels[split:]

print("total train files : ", len(train_files))
print("total valid files : ", len(valid_files))

vocab = list(set("".join(labels)))
vs = len(vocab)
print("total unique characters : ", vs)

ch_to_id = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token="")
id_to_ch = tf.keras.layers.StringLookup(vocabulary=ch_to_id.get_vocabulary(), oov_token="", invert=True)

print("vocab : ", ch_to_id.get_vocabulary())
print("look up size : ", ch_to_id.vocabulary_size())

audios_path = "/content/drive/MyDrive/explorer/main_asr/dataset/recordings_male/"

fl = 256
fs = 160
fftl = 384

def create_data(file, label):

  file = tf.io.read_file(audios_path+file+".wav")
  audio, _ = tf.audio.decode_wav(file)
  # print(audio.shape)
  audio = tf.squeeze(audio, axis=-1)
  # print(audio.shape)
  audio = tf.cast(audio, dtype="float32")

  spec = tf.signal.stft(audio, frame_length=fl, frame_step=fs, fft_length=fftl)
  # print(spec.shape)
  spec = tf.abs(spec)
  spec = tf.math.pow(spec, 0.5)

  mean = tf.math.reduce_mean(spec, 1, keepdims=True)
  stddev = tf.math.reduce_std(spec, 1, keepdims=True)

  spec = (spec-mean)/(stddev+1e-10)

  label = tf.strings.lower(label)
  label = tf.strings.unicode_split(label, "UTF-8")
  label = ch_to_id(label)

  return spec, label

s, l = create_data(train_files[0], train_labels[0])
print(tf.strings.reduce_join(id_to_ch(l)).numpy().decode("utf-8"))

batch_size = 16

train_data = tf.data.Dataset.from_tensor_slices((train_files, train_labels))
train_data = (train_data.map(create_data, num_parallel_calls=tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE))

valid_data = tf.data.Dataset.from_tensor_slices((valid_files, valid_labels))
valid_data = (valid_data.map(create_data, num_parallel_calls=tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE))

for i,o in train_data.take(1):
  print(i.shape)
  print(o.shape)
  break

# ctc loss function
def ctcloss(y_true, y_pred):
  # print("true shape : ", y_true.shape)
  # print("pred shape : ", y_pred.shape)

  batch_len = tf.cast(tf.shape(y_true)[0], dtype="int64")
  label_len = tf.cast(tf.shape(y_true)[1], dtype="int64")
  input_len = tf.cast(tf.shape(y_pred)[1], dtype="int64")

  input_len = input_len * tf.ones(shape=(batch_len, 1), dtype="int64")
  label_len = label_len * tf.ones(shape=(batch_len, 1), dtype="int64")

  loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_len, label_len)
  return loss

# testing each layers to ensure the shape 
tst_inp = layers.Input(shape=(None, fftl//2+1))
print("input shape : ",tst_inp.shape)
re = layers.Reshape((-1, fftl//2+1, 1))(tst_inp)
print("input after reshaping : ",re.shape)
c1 = layers.Conv2D(filters=32, kernel_size=[11,41], strides=[2,2], padding="same", use_bias=False)(re)
print("convolution shape : ", c1.shape)
c2 = layers.Conv2D(filters=32, kernel_size=[11, 21], strides=[1, 2], padding="same", use_bias=False)(c1)
print("convolution 2 shape : ", c2.shape)
re2 = layers.Reshape((-1, c2.shape[-2]*c2.shape[-1]))(c2)
print("reshape 2 shape : ", re2.shape)

# defining and building the model
def model(in_shape, out_shape, rnn_layers=5, rnn_units=128):
  inputs = layers.Input(shape=(None, in_shape))
  x = layers.Reshape((-1, in_shape, 1))(inputs)
  x = layers.Conv2D(filters=32, kernel_size=[11, 41], strides=[2,2], padding="same", use_bias=False)(x)
  x = layers.BatchNormalization()(x)
  x = layers.ReLU()(x)
  x = layers.Conv2D(filters=32, kernel_size=[11, 21], strides=[1, 2], padding="same", use_bias=False)(x)
  x = layers.BatchNormalization()(x)
  x = layers.ReLU()(x)
  x = layers.Reshape((-1, x.shape[-2]*x.shape[-1]))(x)
  
  for i in range(1, rnn_layers+1):
    rnn_gru = layers.GRU(units=rnn_units, activation="tanh", recurrent_activation="sigmoid", use_bias=True, return_sequences=True, reset_after=True)
    x = layers.Bidirectional(rnn_gru, merge_mode="concat")(x)
    if i<rnn_layers:
      x = layers.Dropout(rate=0.5)(x)
  
  x = layers.Dense(rnn_units*2)(x)
  x = layers.ReLU()(x)
  x = layers.Dropout(rate=0.5)(x)
  out = layers.Dense(out_shape+1, activation="softmax")(x)

  model = keras.Model(inputs, out)
  opt = keras.optimizers.Adam(learning_rate=1e-4)
  model.compile(optimizer=opt, loss=ctcloss)

  return model

asr = model(in_shape=fftl//2+1, out_shape=ch_to_id.vocabulary_size(), rnn_units=512)
asr.summary()


# defining callbacks and decode function
def decode(pred):
  input_len = np.ones(pred.shape[0]) * pred.shape[1]
  res = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]
  output = []
  for r in res:
    text = tf.strings.reduce_join(id_to_ch(r)).numpy().decode("utf-8")
    output.append(text)
  return output

y_p = decode(tst_out)
yp = y_p[0]
yt = tf.strings.reduce_join(id_to_ch(o[0])).numpy().decode("utf-8")

class evalCallback(keras.callbacks.Callback):
  def __init__(self, dataset):
    super().__init__()
    self.data = dataset
  
  def on_epoch_end(self, epochs:int, logs=None):
    preds = []
    target = []
    for batch in self.data:
      x, y = batch
      batch_preds = asr.predict(x)
      batch_preds = decode(batch_preds)
      preds.extend(batch_preds)

      for label in y:
        label = (tf.strings.reduce_join(id_to_ch(label)).numpy().decode("utf-8"))
        target.append(label)
    
    wer_score = wer(target, preds)
    print("-" * 100)
    print(f"Word Error Rate: {wer_score:.4f}")
    print("-" * 100)
    for i in np.random.randint(0, len(preds), 2):
        print(f"Target    : {target[i]}")
        print(f"Prediction: {preds[i]}")
        print("-" * 100)


asr.load_weights("/content/tamil_weights.h5")

EPOCHS = 10
eval_cb = evalCallback(valid_data)

asr.fit(train_data, validation_data=valid_data, epochs=EPOCHS, callbacks=[eval_cb])

asr.save_weights("tamilasr_weights.h5")









